{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "433a1a65-e4b4-4800-b513-484eabc8a289",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Importing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "faa7f50f-fdea-4dd4-9e17-146abf393217",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Mounting the Azure Storage container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2d406a4-fabe-4dcc-8293-5f4a3124190e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#  dbutils.fs.mount(\n",
    "#    source = \"wasbs://files@gledisdatabricksstorage1.blob.core.windows.net/\",\n",
    "#    mount_point = \"/mnt/files\",\n",
    "#    extra_configs  = {\"fs.azure.account.key.gledisdatabricksstorage1.blob.core.windows.net\" : \"<storage-account-key>\"}\n",
    "#  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f4fde6fb-7a1f-4243-95bf-a5f4282e52db",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Loading the csv datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "95ab8d1a-491c-4e12-858d-362a9ca3d7bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Initializing all the necessary variables for the dataframes\n",
    "\n",
    "customers = spark.read.csv(\"/mnt/files/olist_customers_dataset.csv\", header=True, inferSchema=True)\n",
    "order_items = spark.read.csv(\"/mnt/files/olist_order_items_dataset.csv\", header=True, inferSchema=True)\n",
    "order_payments = spark.read.csv(\"/mnt/files/olist_order_payments_dataset.csv\", header=True, inferSchema=True)\n",
    "order_reviews = spark.read.csv(\"/mnt/files/olist_order_reviews_dataset.csv\", header=True, inferSchema=True)\n",
    "orders = spark.read.csv(\"/mnt/files/olist_orders_dataset.csv\", header=True, inferSchema=True)\n",
    "products = spark.read.csv(\"/mnt/files/olist_products_dataset.csv\", header=True, inferSchema=True)\n",
    "sellers = spark.read.csv(\"/mnt/files/olist_sellers_dataset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1dd7e86c-2406-4cef-9c92-f52fe11030fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.1: Data cleaning and transformation.\n",
    "- Take each dataset and drop its duplicates for a column(usually primary key/id) and duplicate rows entirely.\n",
    "- Drop rows with missing data in necessary columns that will be used later in creating the fact/detail table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7572ad54-3952-4649-a44b-13bf4c8bffbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "\n",
    "def drop_duplicates_by_column(df, column_name):\n",
    "    \"\"\"\n",
    "    Drops all rows that have duplicate values in the specified column and duplicate rows entirely.\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): The DataFrame from which duplicates will be removed.\n",
    "        column_name (str): The column name to check for duplicates.\n",
    "        \n",
    "    Returns:\n",
    "        pyspark.sql.DataFrame: The cleaned DataFrame with duplicates removed.\n",
    "    \"\"\"\n",
    "    before = df.count()  # Rows before dropping duplicates\n",
    "\n",
    "    if column_name:\n",
    "        df = df.dropDuplicates(subset=[column_name])  # Keep first occurrence without ordering\n",
    "\n",
    "    df = df.dropDuplicates()  # Remove fully duplicate rows\n",
    "\n",
    "    after = df.count()  # Rows after dropping duplicates\n",
    "    print(f\"Removed {before - after} duplicates from '{column_name}' column and overall dataset.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dd8a6048-266d-4647-a5db-4704f69b1620",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customers before: <bound method DataFrame.count of DataFrame[customer_id: string, customer_unique_id: string, customer_zip_code_prefix: int, customer_city: string, customer_state: string]>\nRemoved 3345 duplicates from 'customer_unique_id' column and overall dataset.\nCustomers after: <bound method DataFrame.count of DataFrame[customer_id: string, customer_unique_id: string, customer_zip_code_prefix: int, customer_city: string, customer_state: string]>\n"
     ]
    }
   ],
   "source": [
    "print('Customers before: ' + str(customers.count))\n",
    "customers = drop_duplicates_by_column(customers, 'customer_unique_id')\n",
    "customers = customers.dropna(subset=['customer_unique_id', 'customer_city', 'customer_state', 'customer_zip_code_prefix'])\n",
    "print('Customers after: ' + str(customers.count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "77b11e73-c153-4bb7-9b98-b8e3a217df1a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Products before: <bound method DataFrame.count of DataFrame[product_id: string, product_category_name: string, product_name_lenght: int, product_description_lenght: int, product_photos_qty: int, product_weight_g: int, product_length_cm: int, product_height_cm: int, product_width_cm: int]>\nRemoved 0 duplicates from 'product_id' column and overall dataset.\n+--------------------+---------------------+-------------------+--------------------------+------------------+----------------+-----------------+-----------------+----------------+\n|          product_id|product_category_name|product_name_lenght|product_description_lenght|product_photos_qty|product_weight_g|product_length_cm|product_height_cm|product_width_cm|\n+--------------------+---------------------+-------------------+--------------------------+------------------+----------------+-----------------+-----------------+----------------+\n|00066f42aeeb9f300...|           perfumaria|                 53|                       596|                 6|             300|               20|               16|              16|\n|00088930e925c41fd...|           automotivo|                 56|                       752|                 4|            1225|               55|               10|              26|\n|0011c512eb256aa0d...|           automotivo|                 58|                       177|                 1|             100|               16|               15|              16|\n|00126f27c81360368...|           cool_stuff|                 42|                      2461|                 1|             700|               25|                5|              15|\n|001795ec6f1b187d3...|       consoles_games|                 53|                       274|                 1|             600|               30|               20|              20|\n+--------------------+---------------------+-------------------+--------------------------+------------------+----------------+-----------------+-----------------+----------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "print('Products before: ' + str(products.count))\n",
    "\n",
    "products = drop_duplicates_by_column(products, 'product_id')\n",
    "\n",
    "# Remove products without a category or name.\n",
    "''' \n",
    "There are 2 approaches that can be taken.\n",
    "1. Deleting the products missing a category / name. These could be taken as invalid entries.\n",
    "\n",
    "products = products.dropna(\n",
    "    subset=['product_category_name', \n",
    "            'product_name_lenght', \n",
    "           ])\n",
    "\n",
    "2. Filling in the missing values with a default value, so even category \"No Category \" would show up.\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "products = products.fillna({'product_category_name': 'No Category',\n",
    "                                      'product_name_lenght': '0'})\n",
    "\n",
    "products.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f455961-4ceb-4a7c-be0f-7915b78e21cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicates from 'seller_id' column and overall dataset.\n+--------------------+----------------------+-----------+------------+\n|           seller_id|seller_zip_code_prefix|seller_city|seller_state|\n+--------------------+----------------------+-----------+------------+\n|0015a82c2db000af6...|                  9080|santo andre|          SP|\n|001cca7ae9ae17fb1...|                 29156|  cariacica|          ES|\n|001e6ad469a905060...|                 24754|sao goncalo|          RJ|\n|002100f778ceb8431...|                 14405|     franca|          SP|\n|003554e2dce176b55...|                 74565|    goiania|          GO|\n+--------------------+----------------------+-----------+------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "''' \n",
    "Since the city/address will be used in a SQL Query later on, we should remove all sellers without a city, or put it as N/A\n",
    "sellers = sellers.dropna(subset=['seller_city', 'seller_zip_code_prefix'])\n",
    "'''\n",
    "sellers = drop_duplicates_by_column(sellers, 'seller_id')\n",
    "sellers = sellers.fillna({'seller_city': 'N/A', 'seller_zip_code_prefix': '0000'})\n",
    "\n",
    "sellers.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a771619-2bb0-4ae9-a9a8-891e13fc46a7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicates from '' column and overall dataset.\n"
     ]
    }
   ],
   "source": [
    "# There can be many payments for the same order so only general duplicates should be removed\n",
    "order_payments = drop_duplicates_by_column(order_payments, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a2d6d77f-150f-4b46-9608-c317720b3089",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 0 duplicates from '' column and overall dataset.\n"
     ]
    }
   ],
   "source": [
    "# There can be many items for the same order so only general duplicates should be removed\n",
    "order_items = drop_duplicates_by_column(order_items, '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0efa7fd9-53b3-47f6-9c86-65e3f085ce80",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 1204 duplicates from 'review_id' column and overall dataset.\n"
     ]
    }
   ],
   "source": [
    "order_reviews = drop_duplicates_by_column(order_reviews, 'review_id')\n",
    "order_reviews = order_reviews.dropna(subset=['review_score'])\n",
    "order_reviews = order_reviews.fillna({'review_comment_title': 'No Title Available',\n",
    "                                      'review_comment_message': 'No Comment Available'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cd38f8ca-3636-44d2-8312-cffd17401112",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    },
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Orders before: <bound method DataFrame.count of DataFrame[order_id: string, customer_id: string, order_status: string, order_purchase_timestamp: timestamp, order_approved_at: timestamp, order_delivered_carrier_date: timestamp, order_delivered_customer_date: timestamp, order_estimated_delivery_date: timestamp]>\nRemoved 0 duplicates from 'order_id' column and overall dataset.\nOrders after: <bound method DataFrame.count of DataFrame[order_id: string, customer_id: string, order_status: string, order_purchase_timestamp: timestamp, order_approved_at: timestamp, order_delivered_carrier_date: timestamp, order_delivered_customer_date: timestamp, order_estimated_delivery_date: timestamp]>\n"
     ]
    }
   ],
   "source": [
    "print('Orders before: ' + str(orders.count))\n",
    "\n",
    "orders = drop_duplicates_by_column(orders, 'order_id')\n",
    "\n",
    "# Since we need to calculate the Delivery Time, we need to remove rows missing the following columns: Order Delivered Customer Date, Order Delivered Carrier Date, Order Approved At\n",
    "\n",
    "orders = orders.dropna(subset=['order_purchase_timestamp', 'order_approved_at', 'order_delivered_carrier_date', 'order_delivered_customer_date'])\n",
    "print('Orders after: ' + str(orders.count))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ff492085-85e2-4279-b2c9-88df46b14b2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.2 Creating Calculated Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9d4dd49a-4e99-44f7-bf1e-77de5489c2ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Total Price: Sum of Product Price and Freight Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fd190850-8881-493d-8e02-0295f6183c14",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------------+-------------------+-----+-------------+------------------+\n|            order_id|order_item_id|          product_id|           seller_id|shipping_limit_date|price|freight_value|       total_price|\n+--------------------+-------------+--------------------+--------------------+-------------------+-----+-------------+------------------+\n|00024acbcdf0a6daa...|            1|7634da152a4610f15...|9d7a1d34a50524090...|2018-08-15 10:10:18|12.99|        12.79|             25.78|\n|00010242fe8c5a6d1...|            1|4244733e06e7ecb49...|48436dade18ac8b2b...|2017-09-19 09:45:35| 58.9|        13.29|             72.19|\n|00042b26cf59d7ce6...|            1|ac6c3623068f30de0...|df560393f3a51e745...|2017-02-13 13:57:51|199.9|        18.14|218.04000000000002|\n|000229ec398224ef6...|            1|c777355d18b72b67a...|5b51032eddd242adc...|2018-01-18 14:48:30|199.0|        17.87|            216.87|\n|00048cc3ae777c65d...|            1|ef92defde845ab845...|6426d21aca402a131...|2017-05-23 03:55:27| 21.9|        12.69|34.589999999999996|\n+--------------------+-------------+--------------------+--------------------+-------------------+-----+-------------+------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "order_items = order_items.withColumn('total_price', order_items['price'] + order_items['freight_value'])\n",
    "order_items.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3a74346-eb1e-4f8f-8c8c-4cb975e66cb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Delivery Time: Difference between the delivery date and the order purchase date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "487f04be-4686-48fa-a1c4-912e8143a1de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+------------------+\n|            order_id|         customer_id|order_status|order_purchase_timestamp|  order_approved_at|order_delivered_carrier_date|order_delivered_customer_date|order_estimated_delivery_date|     delivery_time|\n+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+------------------+\n|00018f77f2f0320c5...|f6dd3ec061db4e398...|   delivered|     2017-04-26 10:53:06|2017-04-26 11:05:13|         2017-05-04 14:35:00|          2017-05-12 16:04:24|          2017-05-15 00:00:00|16.216180555555557|\n|00042b26cf59d7ce6...|58dbd0b2d70206bf4...|   delivered|     2017-02-04 13:57:51|2017-02-04 14:10:13|         2017-02-16 09:46:09|          2017-03-01 16:42:31|          2017-03-17 00:00:00| 25.11435185185185|\n|00054e8431b9d7675...|32e2e6ab09e778d99...|   delivered|     2017-12-10 11:53:48|2017-12-10 12:10:31|         2017-12-12 01:07:48|          2017-12-18 22:03:38|          2018-01-04 00:00:00|  8.42349537037037|\n|0006ec9db01a64e59...|5d178120c29c61748...|   delivered|     2018-07-24 17:04:17|2018-07-24 17:24:20|         2018-07-25 11:02:00|          2018-07-31 01:04:15|          2018-08-22 00:00:00| 6.333310185185185|\n|000aed2e25dbad2f9...|fff5169e583fd07fa...|   delivered|     2018-05-11 20:33:38|2018-05-11 20:57:03|         2018-05-16 14:26:00|          2018-05-18 16:46:31|          2018-05-22 00:00:00| 6.842280092592593|\n+--------------------+--------------------+------------+------------------------+-------------------+----------------------------+-----------------------------+-----------------------------+------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "# Calculate the Delivery Time as the difference between the delivered date and the purchase date in days. Add in order_items\n",
    "\n",
    "orders_with_delivery_time = orders.withColumn('order_purchase_timestamp', F.to_timestamp('order_purchase_timestamp'))\n",
    "orders_with_delivery_time = orders_with_delivery_time.withColumn('order_delivered_customer_date', F.to_timestamp('order_delivered_customer_date'))\n",
    "\n",
    "orders_with_delivery_time = orders_with_delivery_time.withColumn('delivery_time', \n",
    "    (F.col('order_delivered_customer_date').cast('long') - F.col('order_purchase_timestamp').cast('long')) / 86400)  # Number of seconds in a day\n",
    "\n",
    "orders_with_delivery_time.show(5)\n",
    "\n",
    "order_items = order_items.join(\n",
    "    orders_with_delivery_time[['order_id', 'delivery_time']], \n",
    "    on='order_id', \n",
    "    how='left'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c4a355b-4187-4230-ad2a-b7e3fb3d9adf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Payment Count: Sum of payment installments for each order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "16c61da0-68cf-4286-afcd-6cc6b787923e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------------+\n|            order_id|total_payment_installments|\n+--------------------+--------------------------+\n|629eb58d177eb9d9e...|                         1|\n|e2b9380fcb4f1f7e2...|                         1|\n|a3797015424a5a231...|                         1|\n|e239d280236cdd3c4...|                         3|\n|f44cb69655f8e4d13...|                         6|\n+--------------------+--------------------------+\nonly showing top 5 rows\n+--------------------+-------------+--------------------+--------------------+-------------------+-----+-------------+------------------+-----------------+--------------------------+\n|            order_id|order_item_id|          product_id|           seller_id|shipping_limit_date|price|freight_value|       total_price|    delivery_time|total_payment_installments|\n+--------------------+-------------+--------------------+--------------------+-------------------+-----+-------------+------------------+-----------------+--------------------------+\n|00024acbcdf0a6daa...|            1|7634da152a4610f15...|9d7a1d34a50524090...|2018-08-15 10:10:18|12.99|        12.79|             25.78|6.147268518518518|                         2|\n|00010242fe8c5a6d1...|            1|4244733e06e7ecb49...|48436dade18ac8b2b...|2017-09-19 09:45:35| 58.9|        13.29|             72.19|7.614421296296296|                         2|\n|00042b26cf59d7ce6...|            1|ac6c3623068f30de0...|df560393f3a51e745...|2017-02-13 13:57:51|199.9|        18.14|218.04000000000002|25.11435185185185|                         3|\n|000229ec398224ef6...|            1|c777355d18b72b67a...|5b51032eddd242adc...|2018-01-18 14:48:30|199.0|        17.87|            216.87|        7.9484375|                         5|\n|00048cc3ae777c65d...|            1|ef92defde845ab845...|6426d21aca402a131...|2017-05-23 03:55:27| 21.9|        12.69|34.589999999999996|6.668067129629629|                         1|\n+--------------------+-------------+--------------------+--------------------+-------------------+-----+-------------+------------------+-----------------+--------------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Group by 'order_id' and sum the 'payment_installments' for each order\n",
    "payment_count = order_payments.groupBy('order_id').agg(\n",
    "    F.sum('payment_installments').alias('total_payment_installments')\n",
    ")\n",
    "payment_count.show(5)\n",
    "\n",
    "# Join the payment_count DataFrame with order_items on order_id\n",
    "order_items = order_items.join(payment_count, on='order_id', how='left')\n",
    "order_items.show(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "755508aa-e7f9-4890-b7b6-3635ae799231",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Profit Margin: Product Price - Freight Value "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f59a5edb-5034-4f4e-bac3-00529a97ffe7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------------+-------------------+-----+-------------+------------------+-----------------+--------------------------+-------------------+\n|            order_id|order_item_id|          product_id|           seller_id|shipping_limit_date|price|freight_value|       total_price|    delivery_time|total_payment_installments|      profit_margin|\n+--------------------+-------------+--------------------+--------------------+-------------------+-----+-------------+------------------+-----------------+--------------------------+-------------------+\n|00024acbcdf0a6daa...|            1|7634da152a4610f15...|9d7a1d34a50524090...|2018-08-15 10:10:18|12.99|        12.79|             25.78|6.147268518518518|                         2|0.20000000000000107|\n|00010242fe8c5a6d1...|            1|4244733e06e7ecb49...|48436dade18ac8b2b...|2017-09-19 09:45:35| 58.9|        13.29|             72.19|7.614421296296296|                         2|              45.61|\n|00042b26cf59d7ce6...|            1|ac6c3623068f30de0...|df560393f3a51e745...|2017-02-13 13:57:51|199.9|        18.14|218.04000000000002|25.11435185185185|                         3|             181.76|\n|000229ec398224ef6...|            1|c777355d18b72b67a...|5b51032eddd242adc...|2018-01-18 14:48:30|199.0|        17.87|            216.87|        7.9484375|                         5|             181.13|\n|00048cc3ae777c65d...|            1|ef92defde845ab845...|6426d21aca402a131...|2017-05-23 03:55:27| 21.9|        12.69|34.589999999999996|6.668067129629629|                         1|  9.209999999999999|\n+--------------------+-------------+--------------------+--------------------+-------------------+-----+-------------+------------------+-----------------+--------------------------+-------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "# Create the 'profit_margin' column by subtracting 'freight_value' from 'price'\n",
    "order_items = order_items.withColumn('profit_margin', F.col('price') - F.col('freight_value'))\n",
    "\n",
    "# Show the results (top rows)\n",
    "order_items.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3bf04b09-1541-4cc5-a91f-2e89ff91911d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.3 Using Window Functions Over Partitions (In pyspark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "79c9f0b1-dc0e-4e43-a1d8-f8a214d0f95b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Total sales per customer, running total of product prices for each customers orders partitioned by customer id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e73a7a35-0c94-4f35-bcd4-1cfad57929d2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------+\n|         customer_id|            order_id|running_total_sales|\n+--------------------+--------------------+-------------------+\n|00050bf6e01e69d5c...|fa906f338cee30a98...|              69.99|\n|000598caf2ef41174...|9b961b894e797f636...|             1107.0|\n|000bf8121c3412d30...|bc3e295306ee4d3eb...|               30.0|\n|00114026c1b7b52ab...|17a9050c446ea78f7...|               49.9|\n|0013cd8e350a7cc76...|4ed7a5d31f58c9c3b...|               79.9|\n+--------------------+--------------------+-------------------+\nonly showing top 5 rows\n+--------------------+--------------------+-------------------+\n|         customer_id|            order_id|running_total_sales|\n+--------------------+--------------------+-------------------+\n|b331b74b18dc79bcd...|11c177c8e97725db2...|             359.98|\n+--------------------+--------------------+-------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Aggregate order_items at the order_id level. Get order_id/price\n",
    "order_totals = order_items.groupBy('order_id').agg(F.sum('price').alias('total_price'))\n",
    "\n",
    "# Merge with orders to get customer_id from orders in a dataframe with total_price in it\n",
    "merged = orders.join(order_totals, on='order_id', how='inner')\n",
    "\n",
    "# Define the window specification that partitions by customer_id and orders by order_id\n",
    "windowSpec = Window.partitionBy('customer_id').orderBy('order_id')\n",
    "\n",
    "# Merge with customer_id window spec to get the running total sales over the specification\n",
    "merged = merged.withColumn('running_total_sales', F.sum('total_price').over(windowSpec))\n",
    "\n",
    "# Select only the customer_id, order_id and running total sales\n",
    "result = merged.select('customer_id', 'order_id', 'running_total_sales')\n",
    "result.show(5)\n",
    "\n",
    "# Filter the result for the specific order_id to show correct calculations\n",
    "filtered_result = result.filter(result['order_id'] == '11c177c8e97725db2631073c19f07b62')\n",
    "filtered_result.show()\n",
    "\n",
    "# order_id 11c177c8e97725db2631073c19f07b62 has 2 orders with each price being 179.99, cumulative sum is shown 359.98"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ae80f88b-badd-423a-b775-f7911e202d68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Average Delivery Time from the moment a customer places an order to when it is delivered to their house\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d06a2d4-54aa-4fc1-be84-9ba7b238c068",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+---------------------+\n|product_category_name|average_delivery_time|\n+---------------------+---------------------+\n|                  pcs|    13.43718592964824|\n|                bebes|    12.45137491616365|\n|          No Category|   12.737630208333334|\n|            cine_foto|                 10.5|\n|                artes|   11.304568527918782|\n+---------------------+---------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Convert timestamps to datetime format and calculate Delivery Time (difference in days)\n",
    "orders = orders.withColumn('order_purchase_timestamp', F.to_timestamp('order_purchase_timestamp'))\n",
    "orders = orders.withColumn('order_delivered_customer_date', F.to_timestamp('order_delivered_customer_date'))\n",
    "orders = orders.withColumn('delivery_time_days', F.datediff('order_delivered_customer_date', 'order_purchase_timestamp'))\n",
    "\n",
    "# Merge order_items, orders, and products dataframes. Order Items is merged with orders to get the delivery time for each order in the order_items dataset. Products is merged with order_items to get the product category name for each order in the order_items dataset.\n",
    "merged = order_items.join(orders.select('order_id', 'delivery_time_days'), on='order_id', how='inner')\n",
    "merged = merged.join(products.select('product_id', 'product_category_name'), \n",
    "                     on='product_id', how='inner')\n",
    "\n",
    "average_delivery_time = merged.groupBy('product_category_name').agg(F.avg('delivery_time_days').alias('average_delivery_time'))\n",
    "\n",
    "\n",
    "average_delivery_time.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e3f3b151-89d8-4801-ac88-4a48a0da59a2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### 4.4: Saving Processed Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d7e76d7-5650-4f48-9d90-98c7a265aa68",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Creating the fact table ( order_items + calculated columns from 4.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "762cb0d3-9589-47ed-8eb2-bec29958cfaa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Reset the dataframes from previous modifications\n",
    "\n",
    "customers = spark.read.csv(\"/mnt/files/olist_customers_dataset.csv\", header=True, inferSchema=True)\n",
    "order_items = spark.read.csv(\"/mnt/files/olist_order_items_dataset.csv\", header=True, inferSchema=True)\n",
    "order_payments = spark.read.csv(\"/mnt/files/olist_order_payments_dataset.csv\", header=True, inferSchema=True)\n",
    "order_reviews = spark.read.csv(\"/mnt/files/olist_order_reviews_dataset.csv\", header=True, inferSchema=True)\n",
    "orders = spark.read.csv(\"/mnt/files/olist_orders_dataset.csv\", header=True, inferSchema=True)\n",
    "products = spark.read.csv(\"/mnt/files/olist_products_dataset.csv\", header=True, inferSchema=True)\n",
    "sellers = spark.read.csv(\"/mnt/files/olist_sellers_dataset.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a56576d7-37ab-4b8c-aa8b-944c20839740",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------+--------------------+--------------------+-------------------+------+-------------+------------------+------------------+--------------------------+-------------------+--------------------+\n|            order_id|order_item_id|          product_id|           seller_id|shipping_limit_date| price|freight_value|       total_price|     delivery_time|total_payment_installments|      profit_margin|         customer_id|\n+--------------------+-------------+--------------------+--------------------+-------------------+------+-------------+------------------+------------------+--------------------------+-------------------+--------------------+\n|00010242fe8c5a6d1...|            1|4244733e06e7ecb49...|48436dade18ac8b2b...|2017-09-19 09:45:35|  58.9|        13.29|             72.19| 7.614421296296296|                         2|              45.61|3ce436f183e68e078...|\n|00018f77f2f0320c5...|            1|e5f2d52b802189ee6...|dd7ddc04e1b6c2c61...|2017-05-03 11:05:13| 239.9|        19.93|            259.83|16.216180555555557|                         3|             219.97|f6dd3ec061db4e398...|\n|000229ec398224ef6...|            1|c777355d18b72b67a...|5b51032eddd242adc...|2018-01-18 14:48:30| 199.0|        17.87|            216.87|         7.9484375|                         5|             181.13|6489ae5e4333f3693...|\n|00024acbcdf0a6daa...|            1|7634da152a4610f15...|9d7a1d34a50524090...|2018-08-15 10:10:18| 12.99|        12.79|             25.78| 6.147268518518518|                         2|0.20000000000000107|d4eb9395c8c0431ee...|\n|00042b26cf59d7ce6...|            1|ac6c3623068f30de0...|df560393f3a51e745...|2017-02-13 13:57:51| 199.9|        18.14|218.04000000000002| 25.11435185185185|                         3|             181.76|58dbd0b2d70206bf4...|\n|00048cc3ae777c65d...|            1|ef92defde845ab845...|6426d21aca402a131...|2017-05-23 03:55:27|  21.9|        12.69|34.589999999999996| 6.668067129629629|                         1|  9.209999999999999|816cbea969fe5b689...|\n|00054e8431b9d7675...|            1|8d4f2bb7e93e6710a...|7040e82f899a04d1b...|2017-12-14 12:10:31|  19.9|        11.85|             31.75|  8.42349537037037|                         1|  8.049999999999999|32e2e6ab09e778d99...|\n|000576fe39319847c...|            1|557d850972a7d6f79...|5996cddab893a4652...|2018-07-10 12:30:45| 810.0|        70.75|            880.75| 5.080324074074074|                        10|             739.25|9ed5e522dd9dd85b4...|\n|0005a1a1728c9d785...|            1|310ae3c140ff94b03...|a416b6a846a117243...|2018-03-26 18:31:29|145.95|        11.65|             157.6| 9.984004629629629|                         3| 134.29999999999998|16150771dfd477626...|\n|0005f50442cb953dc...|            1|4535b0e1091c278df...|ba143b05f0110f0dc...|2018-07-06 14:10:56| 53.99|         11.4|             65.39| 2.145046296296296|                         1|              42.59|351d3cb2cee3c7fd0...|\n|00061f2a7bc09da83...|            1|d63c1011f49d98b97...|cc419e0650a3c5ba7...|2018-03-29 22:28:09| 59.99|         8.88|             68.87| 4.075104166666667|                         3|              51.11|c6fc061d86fab1e2b...|\n|00063b381e2406b52...|            1|f177554ea93259a5b...|8602a61d680a10a82...|2018-07-31 17:30:39|  45.0|        12.98|57.980000000000004| 10.85792824074074|                         5| 32.019999999999996|6a899e55865de6549...|\n|0006ec9db01a64e59...|            1|99a4788cb24856965...|4a3ca9315b744ce9f...|2018-07-26 17:24:20|  74.0|        23.32|             97.32| 6.333310185185185|                         4|              50.68|5d178120c29c61748...|\n|0008288aa423d2a3f...|            1|368c6c730842d7801...|1f50f920176fa81da...|2018-02-21 02:55:52|  49.9|        13.37|63.269999999999996|12.656261574074074|                         1|              36.53|2355af7c75e7c98b4...|\n|0008288aa423d2a3f...|            2|368c6c730842d7801...|1f50f920176fa81da...|2018-02-21 02:55:52|  49.9|        13.37|63.269999999999996|12.656261574074074|                         1|              36.53|2355af7c75e7c98b4...|\n+--------------------+-------------+--------------------+--------------------+-------------------+------+-------------+------------------+------------------+--------------------------+-------------------+--------------------+\nonly showing top 15 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "# 1. Total Price: price + freight_value\n",
    "order_items = order_items.withColumn('total_price', order_items['price'] + order_items['freight_value'])\n",
    "\n",
    "# 2. Calculate the Delivery Time as the difference between the delivered date and the purchase date in days. Add it in order_items dataframe\n",
    "\n",
    "orders_with_delivery_time = orders.withColumn('order_purchase_timestamp', F.to_timestamp('order_purchase_timestamp'))\n",
    "orders_with_delivery_time = orders_with_delivery_time.withColumn('order_delivered_customer_date', F.to_timestamp('order_delivered_customer_date'))\n",
    "\n",
    "orders_with_delivery_time = orders_with_delivery_time.withColumn('delivery_time', \n",
    "    (F.col('order_delivered_customer_date').cast('long') - F.col('order_purchase_timestamp').cast('long')) / 86400)  # Number of seconds in a day\n",
    "\n",
    "order_items = order_items.join(\n",
    "    orders_with_delivery_time[['order_id', 'delivery_time']], \n",
    "    on='order_id', \n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# 3. Payment Count (Total Payment Installments for each order)\n",
    "# Group by 'order_id' and sum the 'payment_installments' for each order\n",
    "payment_count = order_payments.groupBy('order_id').agg(\n",
    "    F.sum('payment_installments').alias('total_payment_installments')\n",
    ")\n",
    "order_items = order_items.join(payment_count, on='order_id', how='left')\n",
    "\n",
    "\n",
    "# 4. Profit Margin: price - freight_value\n",
    "order_items = order_items.withColumn('profit_margin', F.col('price') - F.col('freight_value'))\n",
    "\n",
    "# Populate the fact_table dataframe with all the order_items and customer_id from the orders dataframe. This is needed to query the number of orders from each state from the customer dimension, in order to keep the link: customers <--> orders <--> order_items\n",
    "\n",
    "fact_table = order_items \\\n",
    "    .join(orders.select('order_id', 'customer_id'), on='order_id', how='left')\n",
    "\n",
    "# Display the final fact table\n",
    "fact_table.show(15)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "794c1a15-32c6-40ef-a728-cf564fab2175",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Creating the dimension tables needed. Only date dimension needs to be created. Customers, Products and Sellers are already in a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f10a5801-705c-4258-95b5-e42007b74369",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------------+-----------------------------+\n|            order_id|order_purchase_timestamp|order_delivered_customer_date|\n+--------------------+------------------------+-----------------------------+\n|e481f51cbdc54678b...|     2017-10-02 10:56:33|          2017-10-10 21:25:13|\n|53cdb2fc8bc7dce0b...|     2018-07-24 20:41:37|          2018-08-07 15:27:45|\n|47770eb9100c2d0c4...|     2018-08-08 08:38:49|          2018-08-17 18:06:29|\n|949d5b44dbf5de918...|     2017-11-18 19:28:06|          2017-12-02 00:28:42|\n|ad21c59c0840e6cb8...|     2018-02-13 21:18:39|          2018-02-16 18:17:02|\n+--------------------+------------------------+-----------------------------+\nonly showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "date_dim = orders.select(\n",
    "    'order_id',\n",
    "    'order_purchase_timestamp',\n",
    "    'order_delivered_customer_date'\n",
    ")\n",
    "\n",
    "date_dim.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d0207a54-a5bd-4156-be33-8ae7d76361bd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Write all the dataframes in delta tables in the /mnt/files/deltas directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "52b254fe-57d9-4e4f-80db-665c6eddbb37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames saved to delta tables succesfully.\n"
     ]
    }
   ],
   "source": [
    "customers.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/files/deltas/customers\")\n",
    "products.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/files/deltas/products\")\n",
    "sellers.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/files/deltas/sellers\")\n",
    "fact_table.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/files/deltas/orders\")\n",
    "date_dim.write.format(\"delta\").mode(\"overwrite\").save(\"/mnt/files/deltas/date_dim\")\n",
    "\n",
    "print(\"DataFrames saved to delta tables succesfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f5683856-179f-4779-a599-c94619913734",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Creating the sql tables in order to write the queries needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "199dabbc-18a2-4aa0-844e-f114ab7f2c2a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------+------------------+\n|product_category_name|       total_sales|\n+---------------------+------------------+\n|         beleza_saude|1258681.3400000052|\n|   relogios_presentes|1205005.6800000032|\n|      cama_mesa_banho| 1036988.680000001|\n|        esporte_lazer| 988048.9699999947|\n| informatica_acess...| 911954.3199999924|\n|     moveis_decoracao|  729762.489999984|\n|           cool_stuff|  635290.849999994|\n| utilidades_domest...|   632248.65999999|\n|           automotivo| 592720.1099999945|\n|   ferramentas_jardim|485256.45999999484|\n|           brinquedos|483946.59999999625|\n|                bebes|411764.88999999815|\n|           perfumaria|  399124.869999999|\n|            telefonia|323667.53000000207|\n|    moveis_escritorio| 273960.7000000008|\n|            papelaria| 230943.2300000003|\n|                  pcs|222963.12999999998|\n|             pet_shop|214315.41000000027|\n| instrumentos_musi...| 191498.8800000003|\n|      eletroportateis|190648.58000000007|\n+---------------------+------------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "customers.createOrReplaceTempView(\"customers\")\n",
    "products.createOrReplaceTempView(\"products\")\n",
    "sellers.createOrReplaceTempView(\"sellers\")\n",
    "fact_table.createOrReplaceTempView(\"orders\")\n",
    "date_dim.createOrReplaceTempView(\"date\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "11395d77-ef4c-49f4-9527-2c3ef9e81bca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Query total sales per product category from the fact table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6be2a061-4b2a-4057-bd2e-af13acd6f302",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.sql(\"SELECT p.product_category_name, SUM(o.price) AS total_sales FROM orders o JOIN products p ON o.product_id = p.product_id GROUP BY p.product_category_name ORDER BY total_sales DESC\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4612f3f8-61f7-4d58-b200-2d100ebdb9bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Query the average delivery time per seller from the fact table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1672503e-7830-4aff-8bff-2ee2cf6b8742",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n|           seller_id| avg_delivery_time|\n+--------------------+------------------+\n|ff063b022a9a0aab9...| 9.401329571759259|\n|8e6cc767478edae94...|16.496237675754458|\n|a49928bcdf77c55c6...|16.937956508190883|\n|da7039f29f90ce5b4...| 8.862591306584363|\n|062ce95fa2ad4dfae...|13.336690207156307|\n|2009a095de2a2a416...| 9.829877507716049|\n|0ea22c1cfbdc755f8...|11.021397274633127|\n|6eeed17989b0ae47c...| 6.500030864197531|\n|e63e8bfa530fb1691...| 9.344903273809525|\n|4d600e08ecbe08258...|12.936089616402116|\n|9803a40e82e45418a...|15.709532536008233|\n|b3f19518fcec265b2...| 10.66591724537037|\n|ec8879960bd2221d5...| 16.49511937830688|\n|0b64bcdb0784abc13...| 8.495092592592593|\n|c522be04e020c1e7b...|15.649359567901234|\n|9c068d10aca38e85c...| 16.52933142701525|\n|297d5eccd19fa9a83...| 6.882055844907407|\n|9b1050e85becf3ae9...|               0.0|\n|e38db885400cd35c7...|12.689117476851852|\n|13fa2a6c6b9d0f43c...| 20.52068634259259|\n+--------------------+------------------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT seller_id, IFNULL(AVG(delivery_time), 0) AS avg_delivery_time FROM orders GROUP BY seller_id\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "88fa0bf2-c28e-4a06-a9a5-e98143aedfbf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "- Query the number of orders from each state from the customer dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e5cb9f37-a995-4f04-8449-979ef3490200",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+----------+\n|customer_state|num_orders|\n+--------------+----------+\n|            AC|        92|\n|            AL|       444|\n|            AM|       165|\n|            AP|        82|\n|            BA|      3799|\n|            CE|      1478|\n|            DF|      2406|\n|            ES|      2256|\n|            GO|      2333|\n|            MA|       824|\n|            MG|     13129|\n|            MS|       819|\n|            MT|      1055|\n|            PA|      1080|\n|            PB|       602|\n|            PE|      1806|\n|            PI|       542|\n|            PR|      5740|\n|            RJ|     14579|\n|            RN|       529|\n+--------------+----------+\nonly showing top 20 rows\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT c.customer_state, COUNT(o.order_id) AS num_orders FROM orders o JOIN customers c ON o.customer_id = c.customer_id GROUP BY c.customer_state ORDER BY customer_state ASC\").show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": null,
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "DE",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}